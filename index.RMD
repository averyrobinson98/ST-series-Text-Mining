---
title: "Analysis of Netflix's Stranger Things"
subtitle: "By Avery Robinson"
output:
  rmarkdown::html_document:
    theme: united
    highlight: tango
    toc: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r,include=FALSE}
library(tidytext)
library(dplyr)
library(stringr)
library(textdata)
library(formattable)
library(stringi)
library(tm)
library(forcats)
library(ggplot2)
library(RColorBrewer)
library(wordcloud)
library(reshape2) 
library(tidyr)
library(randomForest)
library(leaps)
library(glmnet)
```

```{r, include=FALSE}
load("originaldata.RDATA")
load("dfForAnalysis.RDATA")
df = df[,-15]
df[is.na(df)] <- 0
df= df[-15,] # Remove outlier episode
```

***

<font size="4"> Netflix's series _Stranger Things_ is one of the most influential shows of the last five years. Over forty million people viewed the third season the weekend of its release -- a Netflix record. To gain insights into my favorite show, I scraped the episode scripts for statistical analysis. I begin my report with descriptive statistics of speaking patterns, move on to word and sentiment analysis, then analze the IMDB ratings for each episode. Next, I use a variety of feature selection techniques as ways to identify variables that help best explain variation in each episode's IMDB rating.  </font>

***

## Analysis

```{r,include=FALSE}
colors <- data.frame(color= c("#0F2970","#5B0000","#4D5463","#22847C","goldenrod2","violetred4","dodgerblue4","#02440F","saddlebrown","mediumvioletred"))
colors$Characters <- factor(MainChars)
```

```{r,fig.width=3.5,fig.height=3,echo=FALSE}

order <- Char_Stats %>% filter(Category=="TotalLines") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))

A <- Char_Stats %>% filter(Category=="TotalLines") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90,color="white")+
                geom_text(aes(label=Value,vjust=-.34),color="white",size=3)+
                theme_dark()+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title.x=element_blank(),axis.title.y=element_blank())+
                geom_text(aes(x="Nancy",y=1050, label="Total Lines"),color="black",size=5)

order <- Char_Stats %>% filter(Category == "AvgLineLength") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))


C <- Char_Stats %>% filter(Category=="AvgLineLength") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90,color="white")+
                geom_text(aes(label=round(Value,1),vjust=-.34),color="white",size=3)+
                theme_dark()+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title.x=element_blank(),axis.title.y=element_blank())+
                geom_text(aes(x="Nancy", y=10.2,label="Average # Words Per Line"),color="black",size=5)

order <- Char_Stats %>% filter(Category == "AvgWordLength") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))

D <- Char_Stats %>% filter(Category=="AvgWordLength") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90,color="white")+
                geom_text(aes(label=round(Value,1),vjust=-.34),color="white",size=3)+
                theme_dark()+
                ylim(0,5)+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title.x=element_blank(),axis.title.y=element_blank())+
                geom_text(aes(x="Hopper", y=5,label="Average Word Length"),color="black",size=5)

order <- Char_Stats %>% filter(Category == "Vocab") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))

E <- Char_Stats %>% filter(Category=="Vocab") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90, color="white")+
                geom_text(aes(label=Value,vjust=-.34),color="white",size=3)+
                theme_dark()+
                ylim(0,1800)+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title=element_blank())+
                geom_text(aes(x="Lucas", y=1770,label="Vocabulary Size"),color="black",size=5)
```

#### Speaking Patterns

***


<font size="3"> To start, I gathered some basic statistics on the main characters' speaking patterns:

</font>

```{r,fig.width=12,fig.height=7,echo=FALSE}
gridExtra::grid.arrange(A,C,D,E,ncol=2)
```

<font size="3"> The first aspect of these graphs that caught my eye was Eleven's top spot in "Average Word Length". I expected her to be near the bottom in each category, yet after further analysis, it is clear that her frequent one-word lines are the reason for this placement. Through the series, Eleven has exactly 150 lines that contain only one word, meaning that she forgoes typical stop words such as "to" and "for" -- words that would decrease her average word length.

I also noted Dustin's placements of first with most total lines and fifth with median number of words per line. This indicates he is a frequent speaker, yet tends not to say too much, which instantly brings back memories of all his "run!"s and "sh\*t"s (Out of all the characters, Dustin has the highest number of "sh\*t"s).
</font>


* * *

#### Season-to-Season Line Proportion Change


<font size="3"> I was interested to find out how the roles of each character changed from season to season. Specifically, I wanted to know if their percentage of lines spoken out of all the main characters fluctuated. </font>

```{r,echo=FALSE}

dark = "aliceblue"
light = "aliceblue"

CharWordCount <- tidy_Chars %>%filter(Season==1) %>% count(Character,sort=T)
season1 <- CharWordCount %>% select(n) %>% unlist %>% unname

CharWordCount <- CharWordCount %>% mutate(total=sum(n))
CharWordCount <- CharWordCount %>% mutate(PropS1 = n/total)

Props <- data.frame(Characters=MainChars,S1=round(CharWordCount$PropS1,3))

CharWordCount <- tidy_Chars %>%filter(Season==2) %>% count(Character,sort=T)
season2 <- CharWordCount %>% select(n) %>% unlist %>% unname

CharWordCount <- CharWordCount %>% mutate(total=sum(n))
CharWordCount <- CharWordCount %>% mutate(PropS2 = n/total)

Props$S2 <- round(CharWordCount$PropS2,3)

CharWordCount <- tidy_Chars %>%filter(Season==3) %>% count(Character,sort=T)
season3 <- CharWordCount %>% select(n) %>% unlist %>% unname

CharWordCount <- CharWordCount %>% mutate(total=sum(n))
CharWordCount <- CharWordCount %>% mutate(PropS3 = n/total)

Props$S3 <- round(CharWordCount$PropS3,3)

Props <- data.frame(t(Props))

Props <- Props[-1,]


Props <- sapply(Props,as.numeric)
Props <- matrix(scales::label_percent(accuracy = .01)(Props), ncol = 10)
Props <- as.data.frame(Props)
colnames(Props) <- MainChars

Props$Season <- factor(1:3)
Props <- Props[,c("Season",MainChars)]
rownames(Props) <- NULL


formattable(Props, list("Season"=formatter("span",style=~style(color="black",font.weight="bold"))))


```

<font size="3">
I performed a chi square test on the raw data to see if the values flucuated in a statistically significant way, and with a p value of 2.2e-16, it can be concluded that the characters' speaking percentages fluctuated with the Season. From the table above, we can see that Eleven contributed much more in seasons 2 and 3 than in season 1, which is where most of her one-word lines happened. We can also see Will's change in contribution from Season 1 to Season 2 and 3, given he spent most of Season 1 in the upside down.

More subtly, we can see that the only two characters that "peaked" in Season 2 were Will and Mike, and that everyone else had their highest speaking percentage in either Season 1 or Season 3.

I was surprised to see that Steve's total percentage for Season 3 was lower than in the other seasons, yet its important to keep in mind that Season 3 had the highest number of lines of all the seasons (Season 3 had 4164 lines, while Season 2 and Season 1 had 3695 and 3413, respectively). Even though Steve had more lines in Season 3, that does not automatically translate to him having a larger proportion of lines from main characters.
</font>

***


#### Word Frequency Analysis

<font size="3"> I then wanted to find patterns in the specific words being used, both by the main characters and in general.</font>

<font size="3"> To start, I filtered out typical _stop_ words such as "and" and "he", calculated the most common words, and was left with the following results: </font>

```{r,echo=FALSE,message=FALSE,fig.width=12}
MostCom <- tidy_all
MostCom <- MostCom %>% count(word,sort=T)

MostCom <- MostCom %>% filter(!word %in% c("yeah","hey","uh","gonna"))

MostCom <- MostCom%>% slice_head(n=300)

MostCom %>%
                ggplot(aes(x="",y=n,label=word,color=n))+
                geom_text(position = position_jitter(seed=130,width=.55),size=6,check_overlap = T,show.legend = T)+
                scale_color_gradient(low="violetred4",high="navy")+
                theme_classic()+
                labs(color="Frequency")+
                ggtitle("Most Common Words")+
                theme_dark()+
                theme(axis.ticks=element_blank(),axis.title = element_blank(),plot.title=element_text(hjust=.5,size=16),axis.line.y=element_blank(),axis.text.x = element_blank())
                
#ggplot2::annotate("segment",x="Will",xend="Dustin",y=1700,yend=1700,colour="black",arrow=arrow())
```

<font size="3"> Naturally, we see many names near the top. The names could have been mentioned in any context, whether the character was being talked to or talked about. We also see other familiar words up top such as "sh\*t", "god", and "guys", which are three of the most common words in the series with counts of 240, 144, and 110, respectively. </font>

***

#### Unique Words Per Character


<font size="3"> I was curious to see how the language in the seasons differed. To find unique words for each season, I used the tf-idf score, which stands for term frequency and inverse document frequency. This score takes into account both the frequency of the word in total and the appearance of the word in separate "documents", which in this case meant seasons. Unfortunately, the top unique words for each season did not reveal interesting information, so instead, I tried the same approach but with characters. Unique words by character yielded much more interesting results, as the table below shows. </font>


```{r,fig.width=15,echo=FALSE,warning=FALSE}
copy <- tidy_Chars %>% count(word,Character)
copy <- copy %>% bind_tf_idf(word,Character,n)
copy <- copy %>% arrange(desc(tf_idf))
top10 <- copy %>% group_by(Character) %>% slice_head(n=12) %>% ungroup
top10 <- top10[-c(11:12,23:24,34:35,43,45,59:60,71:72,83:84,95:96,99,101,114,118),]
top10 <- top10 %>% select(word,Character) 
top10 <- data.frame(top10)

top10$order <- factor(rep(1:10,10))
top10 <- reshape(top10, idvar = "order",timevar = "Character",direction = "wide") %>% data.frame()
top10 <- top10[,-1]
colnames(top10) <- MainChars

formattable(top10,align=c(rep("c",10)),list("Joyce"=formatter("span",style=style(color="#0F2970",font.weight="bold")),
            "Mike"=formatter("span",style=style(color="#5B0000",font.weight="bold")),
            "Hopper"=formatter("span",style=style(color="#4D5463",font.weight="bold")),
            "Nancy"=formatter("span",style=style(color="#22847C",font.weight="bold")),
            "Dustin"=formatter("span",style=style(color="#B58413",font.weight="bold")),
            "Lucas"=formatter("span",style=style(color="#99135A",font.weight="bold")),
            "Jonathan"=formatter("span",style=style(color="#186ABC",font.weight="bold")),
            "Steve"=formatter("span",style=style(color="#02440F",font.weight="bold")),
            "Will"=formatter("span",style=style(color="saddlebrown",font.weight="bold")),
            "Eleven"=formatter("span",style=style(color="mediumvioletred",font.weight="bold"))))

```

<font size="3"> Watchers of the show will observe that the words for the characters do a good job on shining light onto each personality, such as Hopper's "Smirnoff", Eleven's "breather" (frequently heard as mouth breather), and Lucas's "weirdo".


***


#### Similarities in Speech

<font size="3"> I was also curious to find out how similarly the characters speak. I decided to focus on the aspect of common words as a metric for similarity. I found the top 100 common words per character, with _stop_ words filtered out, and calculated the intersection percentage to make the following heat map. </font>

```{r,fig.height=4,echo=FALSE,warning=FALSE,message=FALSE,out.extra='style="float:left; padding:10px"',out.width= "65%"}
ComWords2 <- tidy_Chars %>% anti_join(stop_words)
ComWords2 <- ComWords2 %>% count(Character,word,sort=T)

additionalFilter <- c("yeah","hey","gonna","um","uh")

ComWords2$word <- removeWords(ComWords2$word, additionalFilter)
ComWords2$word[ComWords2$word==""] <- NA
ComWords2 <- ComWords2[complete.cases(ComWords2),]

ComWords2 <- ComWords2 %>% arrange(Character,desc(n))
ComWords2 <- ComWords2 %>% group_by(Character)
ComWords2 = ComWords2 %>% slice_max(Character,n=100,with_ties=FALSE)
ComWords2 = as.data.frame(ComWords2)

ComWords2 <- ComWords2[,-3]
ComWords2$ID = rep(1:100,10)

ComWords2<- spread(ComWords2, Character,word)


ComWords2=ComWords2[,-1]

adjMat <- matrix(NA,ncol=10,nrow=10)
for(i in 1:10){
                for(j in 1:10){
                                adjMat[i,j]<- intersect(ComWords2[i] %>% unlist %>% unname,ComWords2[j] %>% unlist %>% unname) %>% length
                }
}

adjMat[upper.tri(adjMat)] <- NA
adjMat[adjMat==100] <- NA
adjMat <- data.frame(adjMat)

colnames(adjMat) <- MainChars
adjMat$Chars <- MainChars
adjMat <- melt(adjMat)
index <- complete.cases(adjMat)
adjMat <- adjMat[index,]

adjMat %>% mutate(Chars=factor(Chars,levels=MainChars)) %>% 
                ggplot(aes(x=Chars,y=variable,fill=value))+
                geom_tile()+
                guides(fill=guide_colorbar(ticks=F))+
                scale_fill_gradient(low="goldenrod2",high="navyblue",limits=c(10,50),breaks=c(10,50),labels=c("low","high"),aes(fill=""))+
                scale_y_discrete(position = "right")+
                theme_dark()+
                theme(axis.title=element_blank(),legend.position = "right")+
                labs(title="Commonality of Top 100 Most Common Words Per Character")

```

<br>
<font size="3"> With yellow being the lowest similarity, dark blue being the highest, and purple somewhere in the middle, we can see that the two characters with most similar speech are Joyce and Hopper. 
<br><br>
Additionally, Mike's row is one of the most purple, indicating that his word usage overlaps with most of the other characters.
<br><br>
We can also see that the two characters with the least overlap in their top 100 words are Will and Eleven, the two characters with the least amount of lines. Interestly, they also seem to have the fewest words in common with each other than any other pair of characters.
<br><br>
Nancy and Jonathan seem to speak a bit more simalrly to Joyce and Hopper than Lucas, Dustin, Will, or Eleven, yet Steve seems split between the older and younger groups.</font>



***
***

#### Sentiment Analysis


<font size="3"> After the initial word analysis, I wanted to analyze the scripts by sentiment values. Using the afinn library in R, I mapped the sentiment values of the words from each episode to see if there was fluctation.  </font>


```{r,warning=FALSE,echo=FALSE,message=FALSE,fig.width=10}
afinnSents <- get_sentiments("afinn")
afinn <- inner_join(tidy_all, afinnSents)
afinn$value[afinn$word %in% c("god","jesus")] <- -2

afinnEps<- afinn %>% group_by(Episode) %>% summarize(total=sum(value))
afinnEps <- afinnEps %>% mutate(Season=factor(c(rep(1,8),rep(2,9),rep(3,8))))

afinnEps$PosSum<- afinn %>% filter(value > 0) %>% group_by(Episode) %>% summarize(PosSum=sum(value)) %>% select(PosSum) %>% unlist %>% unname
afinnEps$NegSum <- afinn %>% filter(value < 0) %>% group_by(Episode) %>% summarize(NegSum=sum(value)) %>% select(NegSum) %>% unlist %>% unname

ggplot(afinnEps,aes(x=Episode,group=1))+
                geom_area(aes(y=PosSum,fill="#F9D3FF"))+
                geom_area(aes(y=NegSum,fill="#B5B5B5"))+
                geom_line(aes(y=total,color="#F4B41D"),linetype="longdash",size=.4)+
                scale_fill_manual(values=c( "#440154FF","#AA1449"),name=element_blank(),labels=c("Sum of Negatively Indexed Words","Sum of Positively Indexed Words"))+
                scale_color_manual(values="#F4B41D",name=element_blank(),labels="Total Sum of Indexed Scores")+
                theme_dark()+
                theme(legend.position = "right",axis.ticks=element_blank(),legend.text = element_text(size=12),axis.title=element_text(size=12),panel.spacing.y = element_blank())+
                geom_point(aes(y=total,color="#F4B41D"))+
                labs(y="Sentiment Index")+
                scale_x_discrete(limits=c(1:25), expand = c(0, 0)) +
                geom_vline(mapping=aes(xintercept=values),color="gray30",data=SeasonCuts)+
                geom_text(aes(x=c(3,9.5,18.5),y=-400,label=lab),color="#440154FF",size=4,data=SeasonCuts)
```


<font size="3"> In general, Stranger Things tends to have more negatively indexed words than positively indexed words, as we can see from the total sum of the scores. It seems that there tends to be more positively indexed words used near the end of each season, but aside from this, there do not seem to be any obvious patterns. </font>


***

```{r,echo=FALSE,message=FALSE,warning=FALSE,fig.width=5, fig.height=5, out.extra='style="float:left; padding:10px"'}
nrcSents <- get_sentiments("nrc")
ComWords <- tidy_all %>% count(word,sort=T)
ComWords <- ComWords %>% inner_join(nrcSents,by="word")
ComWords <- ComWords %>% filter(!(word == "god" & sentiment %in% c("joy", "positive","trust"))) %>% filter(!(word=="dart")) #doesn't make sense for ST

cols <- viridis::magma(8)
#c("#CC0259","#DDB800","#A50092","#1300A5","#04B1D3","#94B0B2","#9494B2","#A886AA")
cols[8] <- "maroon4"

set.seed(123)
ComWords %>%
                filter(!(sentiment %in% c("positive","negative"))) %>%
                acast(word~sentiment, value.var = "n",fill=0) %>%
                comparison.cloud(random.order = F,max.words=200,colors=cols,match.colors = T, scale=c(4,.5),title.bg.colors = "gray84",title.size=1.5,min.freq=10)

```


<font size="3"> Next, I wanted to go back to the show's most frequent words and break them up into sentiment categories as categorized by the NRC library in R. The top 200 non-neutral words of the series are encompassed in the word cloud to the left. As we can see, the most prolific categories are probably suprise and joy. I found this surprising, expecially considering the entire season sentiment graph just above.  </font>

<font size="3"> After further analysis, it seems that, while the majority of words used are negatively indexed, the range of positive words is higher than the range of negative words. </font>

<br><br><br><br><br><br><br><br><br><br>

***


<font size="3"> I then wanted to return to the most common words for each character and categorize them according to the NRC sentiment library in order to discover any patterns for which characters frequently used words with certain sentiment values. </font>

```{r,echo=FALSE,warning=FALSE,message=FALSE,fig.width=10,error=FALSE}
sent_ComWords <- data.frame()

for(i in 1:10){
                temp <- ComWords2[[i]] %>% unlist %>% data.frame()
                temp <- left_join(temp, nrcSents %>% filter(!sentiment %in% c("positive","negative"))  ,by=c("."="word"))
                temp$Char <- rep(i,length(dim(temp)[1]))
                sent_ComWords <- bind_rows(sent_ComWords,temp)
}

temp <- data.frame(Chars=MainChars,CharNum=1:10)

sent_ComWords <- left_join(sent_ComWords,temp,by=c("Char"="CharNum"))
sent_ComWords <- sent_ComWords[,-3]
names(sent_ComWords) <- c("word","sentiment","char")
sent_ComWords$char <- factor(sent_ComWords$char)

sent_ComWords <- sent_ComWords %>% count(sentiment,char)
sent_ComWords<- sent_ComWords %>% pivot_wider(names_from = char,values_from=n) %>% data.frame()
sents <- sent_ComWords$sentiment
sent_ComWords<- data.frame(sapply(sent_ComWords[,-1],function(x) x/sum(x,na.rm=T)))
sent_ComWords$Sentiment <- factor(sents)
dup <- sent_ComWords
sent_ComWords <- sent_ComWords %>% pivot_longer(!Sentiment)



order <- sent_ComWords[is.na(sent_ComWords$Sentiment),] %>% select(name,value) %>% arrange(value) %>% select(name) %>% unlist() %>% unname

col <- viridis::magma(8)

sent_ComWords %>% mutate(name=factor(name,levels=order)) %>% 
ggplot(aes(x=name,y=value,fill=Sentiment))+
                geom_bar(stat = "identity")+
                scale_fill_manual(values=col,na.value="#545454",labels=c("Anger                  Highest:Dustin","Anticipation         Highest:Steve","Disgust                Highest:Joyce","Fear                    Highest:Eleven","Joy                      Highest:Eleven","Sadness              Highest:Eleven","Surprise              Highest:Will","Trust                   Highest:Eleven","Neutral                Highest:Hopper"))+
                theme_minimal()+
                labs(y="Percent")+
                theme_dark()+
                theme(axis.title.x=element_blank())
```

<font size="3">  As mentioned earlier, Eleven has the most one-word lines of the show. While this drives up her word length average, I  also believe this gives her the lowest percentage of neutral words, as she forgoes many common words that also might not be classified as _stop_ words. This could contribute to why she has the highest percentage of fear, joy, sadness, and trust words. Additionally, Dustin's fiery dynamic makes his placement as top percentage of anger words unsurprising. Aside from a few notable differences, the percentages across characters are similar. </font>

***

#### IMDB Rating Analysis

<font size="3"> Finally, I was curious to see how the ratings of each episode fluctated as the series progressed. I scraped the episode ratings from IMDB and got the following results: </font>

```{r, echo=FALSE,out.extra='style="float:left; padding:10px"',out.width= "65%"}
ratings$Season <- factor(EpsbySeason$Season)
temp <- ratings
temp$Episode <- str_replace_all(ratings$Episode,"_"," ")


temp %>% mutate(Episode= factor(Episode, levels=rev(Episode))) %>% 
                ggplot(aes(x=Episode,y=Ratings))+
                geom_segment(aes(col=Season,y=mean(ratings$Ratings), x=Episode, yend=Ratings, xend= Episode),size=1.5)+
                scale_colour_manual(values=c("#440154FF","#D8006C","#EAC300"))+
                geom_hline(mapping=aes(yintercept=mean(ratings$Ratings)),color="black")+
                geom_label(label=ratings$Ratings,nudge_x =0,nudge_y = 0,size=2)+
                ylim(6,9.5)+
                coord_flip()+
                labs(title="IMDB Episode Rating")+
                theme_dark()+
                theme(axis.title.y=element_blank(),plot.title = element_text(hjust=0.5,size=10))
```


```{r,fig.height=4,echo=FALSE,warning=FALSE,message=FALSE,out.extra='style="float:left; padding:10px"',out.width= "65%"}
Chars <- str_extract(AllLines$Lines,"\\w*(?=:)")
Chars <- data.frame(chars=Chars,Episode=AllLines$Episode)

MainChars2 <- c(MainChars,"Bob","Billy","Max","Robin")

LinesByMainChars <- Chars %>% group_by(Episode) %>% summarize(percent=sum(chars %in% MainChars2)/n()) %>% data.frame()

LinesByMainChars$Season <- factor(EpsbySeason$Season)
LinesByMainChars$Rating <-ratings$Ratings
Chars <- NULL

ggplot(LinesByMainChars,aes(x=Episode,group=1))+
                geom_line(aes(y=percent*10,color="Percent of Lines from Main Characters"),size=1.3)+
                geom_line(aes(y=Rating,color="Episode Rating"),size=1.3)+
                theme_gray()+
                scale_color_manual(values=c("#00004d","#009999"),name=element_blank())+
                scale_y_continuous(name="Percent By Main Characters",breaks=c(1:10),labels=seq(.1,1,.1),sec.axis = sec_axis(trans=~.*10,name="Episode Rating",breaks=c(seq(10,100,10)), labels=c(1:10)))+
                theme_dark()+
                theme(axis.title.y.left=element_text(size=9,hjust=1,vjust=2.5),,axis.title.y.right = element_text(size=9,hjust=0,vjust=2.5),legend.position = "bottom")+
                geom_vline(mapping=aes(xintercept=values),color="gray30",data=SeasonCuts)+
                geom_text(aes(x=c(3,10.5,19.5),y=3,label=lab),color="black",size=3,data=SeasonCuts)
```

<br>
<font size="3"> The trend in ratings is one of the most clear trends thus far. Given that each season represents its own color, the graph shows that IMDB scores tend to increase as the season progresses. The black vertical line represents the average of all the ratings, so we see that episodes tend to be below average the first few episodes of the season and above average for the last few episodes of the season. The exception to this trend is Episode 7 of Season 2: The Lost Sister. In this episode, Eleven leaves Hawkins to seek out her sister from the laboratory.</font>

<br>
<font size="3"> The low rating of the Lost Sister episode made me wonder if episodes that contained a higher percentage of lines from main characters had higher ratings. I calculated the percentage of lines spoken by main characters for each episode (with Max, Billy, Robin and Bob counting as main characters) and got the following results. </font>

<br>
<font size="3"> The lines somewhat follow each other, yet most notably at The Lost Sister episode. I would guess that, after removing the outlier episode, the correlation would be much weaker. </font>


<br><br>


***
***




## Feature Selection

<font size="3">
It is clear that episode placement within each season is influential on an episode's IMDB rating, but I was curious to find out which of the other statistics mentioned above could help explain variation in the rating of each episode. Due to the dimensionality of the data (33 predictors to 24 observations), typical techniques such as Analysis Of Variance (ANOVA) and Ordinary Least Squares regression were not optimal. In order to find out which variables were important, I began with the correlations of each numerical predictor with the independent variable of IMDB rating: 
</font>
```{r,echo=FALSE}
tab = cor(df[,4],df[,-c(1,3:4)])
tab = data.frame("Var"=colnames(tab),"Cor"=as.vector(tab))
tab = arrange(tab,desc(abs(Cor)))
formattable(tab[1:10,],align=rep("l",7))
```
<font size="3">
These correlations give us a good idea as to which variables are important, but they do not account for nonlinear relationships. To explore the problem further, I used a variety of different techniques to see if their answer to the question of which variables are most important fluctuated from the correlations list. I started by using forward stepwise selection. Then, as a way to get "more input" on which variables were important, I used a variety of other techniques, typically used for prediction, that still had some feature selection properties: random forests, ridge regression, and lasso regression. </font>

<br>

#### Forward Step-Wise Selection

<font size="3">
To implement forward stepwise selection , I built several optimal models with varying numbers of features using a greedy algorithm. Roughly speaking, we can think of the order in which variables are added as an order of importance of the variables, but only in a general sense -- if the variables are highly correlated, this will not be reliable. 

The graph below shows us the R^2 value on the y-axis and the variables on the x-axis. For each level of R^2 in the graph, the variables used to achieve that level of R^2 are represented by black boxes.
</font>
```{r,echo=FALSE,results=FALSE,warning=FALSE,message=FALSE}
set.seed(11)
index = sample(1:24,18,replace = FALSE)
train = df[index,]
test = df[-index,]
errors = rep(NA,11)
regfit.fwd=regsubsets(Rating~.,data=train[,-1],nvmax=11,method="forward")

plot(regfit.fwd,scale="r2")
```
<font size="3">
<br><br>
As we can see, there are a few variables that do the bulk of the work in explaining variation, and a few others that add bit by bit. If we consider only episode placement, number of words spoken by Joyce, number of lines from Nancy, and whether the episode was in season 2 or not, we can explain a sizeable chunk of the variation.

Step-wise selection does not guarantee the perfect set of predictors, both because of the nature of greedy algorithms and issues with correlated variables. Still, we can use our results as a general guide. 

Variables of importance according to forward step-wise selection:</font>
<br>

* Episode Placement
* Number of words spoken by Joyce
* Number of lines from Nancy
* Season

<br>
<br>

#### Random Forests

<font size="3"> The next method I used was random forests. Through creating 500 trees, we can see which variables were used most often to explain an episode's rating. 
</font>

```{r,echo=FALSE,include=FALSE}
rf.df = randomForest(Rating~.,data=df[,-1],nvmax=6,importance=T)
A <- varImpPlot(rf.df)
A <- as.data.frame(A)
A$Variable = rownames(A)
names(A) <- c("Perc.IncMSE","IncNodePurity","Variable")

```

```{r,fig.height=4,echo=FALSE,warning=FALSE,message=FALSE}
cols=viridis::magma(32)

A %>% mutate(Variable=fct_reorder(Variable,desc(IncNodePurity))) %>%
                ggplot(aes(x=Variable,y=IncNodePurity,fill=IncNodePurity))+
                geom_bar(stat="identity",aes(fill=IncNodePurity))+
                scale_fill_viridis_c(direction = -1)+
                theme_classic()+
                ggtitle("Importance of Variables Determined by Random Forest")+
                theme(axis.text.x = element_text(angle=90),axis.title.x=element_blank(),axis.title.y = element_blank(),plot.title = element_text(hjust=.5),legend.position = "none")

```

<font size="3">
The graph above plots the mean decrease in the gini index against the variables. The higher the value the average decrease in the gini index a variable has, the more important the variable is at explaining variation in ratings.

From the graph above, we can conclude that, according to random forests, the most important variables in explaining variation in ratings are as follows:
<br>
</font>

* Episode Placement
* Dustin's number of lines 
* Fear 


<br>


#### Ridge Regression as a Variable selector

<font size="3"> Next, I used ridge regression as a way to find important variables. Ridge regression will shrink the coefficients associated with variables that should have less influence on the model. After performing ridge regression, we can think of the variables with the largest coefficients as, by a certain measure, the more important features. </font>
```{r,echo=FALSE,warning=FALSE}
#Ridge

X.scaled = scale(df[,-c(1,3)])
df.scaled = data.frame(X.scaled, df[,3])

X = model.matrix(Rating~.,data=df.scaled)
y= df$Rating
ridge.Model = glmnet(X,y,alpha=0)
cv.ridge = cv.glmnet(X,y,alpha=0)
bestlambda = cv.ridge$lambda.min
x <- sort(round(abs(predict(ridge.Model, s=bestlambda,type="coefficients")[1:32,]),2),decreasing = TRUE)
x <- data.frame("Variable"=names(x),"Coefficient"=unname(x))
x <- x[-1,]
x <- x %>% filter(abs(Coefficient)!=0)
formattable(x,align=c(rep("l",10)))

```
<font size="3"> The table above shows the variables of the model that did not round to zero (using two decimals of precision). 
Important Variables Determined by Ridge Regression: </font>
<br>

* Episode Placement
* Fear


#### Lasso Regression as a Variable selector
<font size="3"> 
Finally, I used Lasso Regression as my last method of identifying important variables. Lasso regression is also a shrinkage method, and we can interpret the results similarly to the results of ridge regression: the largest coefficienst are associated with the variables of most importance.
</font>

```{r,warnings=FALSE,echo=FALSE,warning=FALSE}
lasso.Model = glmnet(X,y,alpha=1)
cv.lasso = cv.glmnet(X,y,alpha=1)
bestlambda = cv.lasso$lambda.min
x=sort(round(abs(predict(lasso.Model, s=bestlambda, type="coefficients")[1:32,]),2),decreasing = TRUE)
x <- data.frame("Variable"=names(x),"Coefficient"=unname(x))
x <- x[-1,]
x <- x %>% filter(abs(Coefficient)!=0)
formattable(x,align=c(rep("l",10)))
```
<font size="3"> The output above show the coefficients that, with three digits of percision, did not round to zero. In summary and according to Lasso, the important variables in explaining IMDB ratings are the following: </font>
<br>

* Episode Placement
* Number of Words from Joyce
* Fear
* Disgust

<br>

***

#### Feature Selection Summary

<font size="3"> Each method of feature selection gives slightly differing results, yet all of them included features on the list of the top ten correlations. We can conclude that, for this dataset, correlations did a good job at indicating important features. The different techniques, however, did show us that there are predictor variables that are highly correlated with each other. The reason that we do not see all of the ten variables from the correlation list in each of the output for the four different techniques is that some of the variation that one variable may "explain" could have already been explained by another variable -- this is known as multicollinearity.

Keeping in mind the multicollinearity problems and both the output of the top ten correlated variables list and the output from the four different technqiues, we can be confident that three of the most important variables in explaining an episode's IMDB rating are the episode's placement in the season, the season the episode came from, and the percent of words with a sentiment value of fear.

***
***






