---
title: "Analysis of Netflix's Stranger Things"
subtitle: "By Avery Robinson"
output:
  rmarkdown::html_document:
    theme: united
    highlight: tango
    toc: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r,include=FALSE}
library(tidytext)
library(dplyr)
library(stringr)
library(textdata)
library(formattable)
library(stringi)
library(tm)
library(forcats)
library(ggplot2)
library(RColorBrewer)
library(wordcloud)
library(reshape2) 
library(tidyr)
library(randomForest)
library(leaps)
library(glmnet)
```

```{r, include=FALSE}
load("originaldata.RDATA")
load("dfForAnalysis.RDATA")
df = df[,-15]
df[is.na(df)] <- 0
df= df[-15,] # Remove outlier episode
```

***

<font size="4"> Netflix's series _Stranger Things_ is one of the most influential shows of the last five years. Over forty million people viewed the third season the weekend of its release -- a Netflix record. To gain insights into my favorite show, I scraped the episode scripts for statistical analyses. I begin my report with general statistics, move on to word and sentiment analysis, and then analyze the IMDB ratings for each episode. Next, I use a variety of feature selection techniques as ways to identify variables that help best explain variation in each episode's IMDB rating.  </font>

***

## Analysis

```{r,include=FALSE}
colors <- data.frame(color= c("#0F2970","#5B0000","#4D5463","#22847C","goldenrod2","violetred4","dodgerblue4","#02440F","saddlebrown","mediumvioletred"))
colors$Characters <- factor(MainChars)
```

```{r,fig.width=3.5,fig.height=3,echo=FALSE}

order <- Char_Stats %>% filter(Category=="TotalLines") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))

A <- Char_Stats %>% filter(Category=="TotalLines") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90,color="white")+
                geom_text(aes(label=Value,vjust=-.34),color="white",size=3)+
                theme_dark()+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title.x=element_blank(),axis.title.y=element_blank())+
                geom_text(aes(x="Nancy",y=1050, label="Total Lines"),color="black",size=5)

order <- Char_Stats %>% filter(Category == "AvgLineLength") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))


C <- Char_Stats %>% filter(Category=="AvgLineLength") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90,color="white")+
                geom_text(aes(label=round(Value,1),vjust=-.34),color="white",size=3)+
                theme_dark()+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title.x=element_blank(),axis.title.y=element_blank())+
                geom_text(aes(x="Nancy", y=10.2,label="Average # Words Per Line"),color="black",size=5)

order <- Char_Stats %>% filter(Category == "AvgWordLength") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))

D <- Char_Stats %>% filter(Category=="AvgWordLength") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90,color="white")+
                geom_text(aes(label=round(Value,1),vjust=-.34),color="white",size=3)+
                theme_dark()+
                ylim(0,5)+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title.x=element_blank(),axis.title.y=element_blank())+
                geom_text(aes(x="Hopper", y=5,label="Average Word Length"),color="black",size=5)

order <- Char_Stats %>% filter(Category == "Vocab") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))

E <- Char_Stats %>% filter(Category=="Vocab") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90, color="white")+
                geom_text(aes(label=Value,vjust=-.34),color="white",size=3)+
                theme_dark()+
                ylim(0,1800)+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title=element_blank())+
                geom_text(aes(x="Lucas", y=1770,label="Vocabulary Size"),color="black",size=5)
```

#### Character Statistics

***


<font size="3"> To start, I gathered some basic statistics on the main characters' speaking patterns:

</font>

```{r,fig.width=12,fig.height=7,echo=FALSE}
gridExtra::grid.arrange(A,C,D,E,ncol=2)
```

<font size="3"> The first aspect of these graphs that caught my eye was Eleven's top spot in "Average Word Length". I expected her to be near the bottom in each category, yet after further analysis, it is clear that her frequent one-word lines is the reason for this placement. Through the series, Eleven has exactly 150 lines that contain only one word, meaning that she forgoes typical stop words such as "to" and "for" -- words that would bring down her average word length.

I also noted Dustin's placements of first with most total lines and fifth with median number of words per line. This indicates he is a frequent speaker, yet tends not to say too much, which instantly brings back memories of all his "run!"s and "sh\*t"s (Out of all the characters, Dustin has the highest number of "sh\*t"s).
</font>


* * *

#### Season-to-Season Line Proportion Change


<font size="3"> I was interested to find out how the roles of each character changed from season to season. Specifically, I wanted to know if their percentage of lines spoken out of all the main characters fluctuated. </font>

```{r,echo=FALSE}

dark = "aliceblue"
light = "aliceblue"

CharWordCount <- tidy_Chars %>%filter(Season==1) %>% count(Character,sort=T)
season1 <- CharWordCount %>% select(n) %>% unlist %>% unname

CharWordCount <- CharWordCount %>% mutate(total=sum(n))
CharWordCount <- CharWordCount %>% mutate(PropS1 = n/total)

Props <- data.frame(Characters=MainChars,S1=round(CharWordCount$PropS1,3))

CharWordCount <- tidy_Chars %>%filter(Season==2) %>% count(Character,sort=T)
season2 <- CharWordCount %>% select(n) %>% unlist %>% unname

CharWordCount <- CharWordCount %>% mutate(total=sum(n))
CharWordCount <- CharWordCount %>% mutate(PropS2 = n/total)

Props$S2 <- round(CharWordCount$PropS2,3)

CharWordCount <- tidy_Chars %>%filter(Season==3) %>% count(Character,sort=T)
season3 <- CharWordCount %>% select(n) %>% unlist %>% unname

CharWordCount <- CharWordCount %>% mutate(total=sum(n))
CharWordCount <- CharWordCount %>% mutate(PropS3 = n/total)

Props$S3 <- round(CharWordCount$PropS3,3)

Props <- data.frame(t(Props))

Props <- Props[-1,]


Props <- sapply(Props,as.numeric)
Props <- matrix(scales::label_percent(accuracy = .01)(Props), ncol = 10)
Props <- as.data.frame(Props)
colnames(Props) <- MainChars

Props$Season <- factor(1:3)
Props <- Props[,c("Season",MainChars)]
rownames(Props) <- NULL


formattable(Props, list("Season"=formatter("span",style=~style(color="black",font.weight="bold"))))


```

<font size="3">
I performed a chi square test on the raw data to see if the values flucuated in a statistically significant way, and with a p value of 2.2e-16, it can be concluded that the characters' speaking percentages fluctuated with the Season. From the table above, we can see that Eleven contributed much more in seasons 2 and 3 than in season 1, which is where most of her one-word lines happened. We can also see Will's change in contribution from Season 1 to Season 2 and 3, given he spent most of Season 1 in the upside down.

More subtly, we can see that the only two characters that "peaked" in Season 2 were Will and Mike, and that everyone else had their highest speaking percentage in either Season 1 or Season 3.

I was surprised to see that Steve's total percentage for Season 3 was lower than in the other seasons, yet its important to keep in mind that Season 3 had the highest number of lines of all the seasons (Season 3 had 4164 lines, while Season 2 and Season 1 had 3695 and 3413, respectively). Even though Steve had more lines in Season 3, that does not automatically translate to him having a larger proportion of lines from main characters.
</font>

***


#### Word Frequency Analysis

<font size="3"> I then wanted to find patterns in the specific words being used, both by the main characters and in general.</font>

<font size="3"> To start, I filtered out typical _stop_ words such as "and" and "he", calculated the most common words, and was left with the following results: </font>

```{r,echo=FALSE,message=FALSE,fig.width=12}
MostCom <- tidy_all
MostCom <- MostCom %>% count(word,sort=T)

MostCom <- MostCom %>% filter(!word %in% c("yeah","hey","uh","gonna"))

MostCom <- MostCom%>% slice_head(n=300)

MostCom %>%
                ggplot(aes(x="",y=n,label=word,color=n))+
                geom_text(position = position_jitter(seed=130,width=.55),size=6,check_overlap = T,show.legend = T)+
                scale_color_gradient(low="violetred4",high="navy")+
                theme_classic()+
                labs(color="Frequency")+
                ggtitle("Most Common Words")+
                theme_dark()+
                theme(axis.ticks=element_blank(),axis.title = element_blank(),plot.title=element_text(hjust=.5,size=16),axis.line.y=element_blank(),axis.text.x = element_blank())
                
#ggplot2::annotate("segment",x="Will",xend="Dustin",y=1700,yend=1700,colour="black",arrow=arrow())
```

<font size="3"> Naturally, we see many names near the top. The names could have been mentioned in any context, whether the character was being talked to or talked about. We also see other familiar words up top such as "sh\*t", "god", and "guys", which are the most common words in the series with counts of 240, 144, and 110, respectively. </font>

***

#### Unique Words Per Character


<font size="3"> I was curious to see how the language in the seasons differed. To find unique words for each season, I used the tf-idf score, which stands for term frequency and inverse document frequency. This score takes into account both the frequency of the word in total and the appearance of the word in separate "documents", which in this case meant seasons. Unfortunately, the top unique words for each season did not reveal interesting information, so instead, I tried the same approach but with characters. Unique words by character yielded much more interesting results, as the table below shows. </font>


```{r,fig.width=15,echo=FALSE,warning=FALSE}
copy <- tidy_Chars %>% count(word,Character)
copy <- copy %>% bind_tf_idf(word,Character,n)
copy <- copy %>% arrange(desc(tf_idf))
top10 <- copy %>% group_by(Character) %>% slice_head(n=12) %>% ungroup
top10 <- top10[-c(11:12,23:24,34:35,43,45,59:60,71:72,83:84,95:96,99,101,114,118),]
top10 <- top10 %>% select(word,Character) 
top10 <- data.frame(top10)

top10$order <- factor(rep(1:10,10))
top10 <- reshape(top10, idvar = "order",timevar = "Character",direction = "wide") %>% data.frame()
top10 <- top10[,-1]
colnames(top10) <- MainChars

formattable(top10,align=c(rep("c",10)),list("Joyce"=formatter("span",style=style(color="#0F2970",font.weight="bold")),
            "Mike"=formatter("span",style=style(color="#5B0000",font.weight="bold")),
            "Hopper"=formatter("span",style=style(color="#4D5463",font.weight="bold")),
            "Nancy"=formatter("span",style=style(color="#22847C",font.weight="bold")),
            "Dustin"=formatter("span",style=style(color="#B58413",font.weight="bold")),
            "Lucas"=formatter("span",style=style(color="#99135A",font.weight="bold")),
            "Jonathan"=formatter("span",style=style(color="#186ABC",font.weight="bold")),
            "Steve"=formatter("span",style=style(color="#02440F",font.weight="bold")),
            "Will"=formatter("span",style=style(color="saddlebrown",font.weight="bold")),
            "Eleven"=formatter("span",style=style(color="mediumvioletred",font.weight="bold"))))

```

<font size="3"> Watchers of the show will observe that the words for the characters do a good job on shining light onto each personality, such as Hopper's "Smirnoff", Eleven's "breather" (frequently heard as mouth breather), and Lucas's "weirdo".


***


#### Similarities in Speech

<font size="3"> I enjoyed seeing the unique words each character use, but I was also curious to find out how similarly the characters speak. To narrow it down, I decided to focus on the aspect of common words. I found the top 100 common words per character, with _stop_ words filtered out, and calculated the intersection percentage to make the following heat map. </font>

```{r,out.width= "65%", out.extra='style="float:left; padding:10px"',echo=FALSE,warning=FALSE,message=FALSE}
ComWords2 <- tidy_Chars %>% anti_join(stop_words)
ComWords2 <- ComWords2 %>% count(Character,word,sort=T)

additionalFilter <- c("yeah","hey","gonna","um","uh")

ComWords2$word <- removeWords(ComWords2$word, additionalFilter)
ComWords2$word[ComWords2$word==""] <- NA
ComWords2 <- ComWords2[complete.cases(ComWords2),]

ComWords2 <- ComWords2 %>% arrange(Character,desc(n))
ComWords2 <- ComWords2 %>% group_by(Character) %>% slice_head(word,n=100)
ComWords2 <- ComWords2[,-3]
ComWords2 <- ComWords2 %>% pivot_wider(names_from=Character,values_from=word)


adjMat <- matrix(NA,ncol=10,nrow=10)
for(i in 1:10){
                for(j in 1:10){
                                adjMat[i,j]<- intersect(ComWords2[i] %>% unlist %>% unname,ComWords2[j] %>% unlist %>% unname) %>% length
                }
}

adjMat[upper.tri(adjMat)] <- NA
adjMat[adjMat==100] <- NA
adjMat <- data.frame(adjMat)

colnames(adjMat) <- MainChars
adjMat$Chars <- MainChars
adjMat <- melt(adjMat)
index <- complete.cases(adjMat)
adjMat <- adjMat[index,]

adjMat %>% mutate(Chars=factor(Chars,levels=MainChars)) %>% 
                ggplot(aes(x=Chars,y=variable,fill=value))+
                geom_tile()+
                guides(fill=guide_colorbar(ticks=F))+
                scale_fill_gradient(low="goldenrod2",high="navyblue",limits=c(10,50),breaks=c(10,50),labels=c("low","high"),aes(fill=""))+
                scale_y_discrete(position = "right")+
                theme_dark()+
                theme(axis.title=element_blank(),legend.position = "right")+
                labs(title="Commonality of Top 100 Most Common Words Per Character")

```

<br>
<font size="3"> With yellow being the lowest similarity, dark blue being the highest, and purple somewhere in the middle, we can see that the two characters with most similar speech are Joyce and Hopper. 
<br><br>
Additionally, Mike's row is one of the most purple, indicating that his word usage overlaps with most of the other characters.
<br><br>
We can also see that the two characters with the least overlap in their top 100 words are Will and Eleven, the two characters with the least amount of lines. Interestly, they also seem to have the fewest words in common with each other than any other pair of characters.
<br><br>
Nancy and Jonathan seem to speak a bit more simalrly to Joyce and Hopper than Lucas, Dustin, Will, or Eleven, yet Steve seems split between the older and younger groups.</font>



***
***

#### Sentiment Analysis


<font size="3"> After the initial word analysis, I wanted to analyze the scripts by sentiment values. Using the afinn library in R, I mapped the sentiment values of the words from each episode to see if there was fluctation.  </font>


```{r,warning=FALSE,echo=FALSE,message=FALSE,fig.width=10}
afinnSents <- get_sentiments("afinn")
afinn <- inner_join(tidy_all, afinnSents)
afinn$value[afinn$word %in% c("god","jesus")] <- -2

afinnEps<- afinn %>% group_by(Episode) %>% summarize(total=sum(value))
afinnEps <- afinnEps %>% mutate(Season=factor(c(rep(1,8),rep(2,9),rep(3,8))))

afinnEps$PosSum<- afinn %>% filter(value > 0) %>% group_by(Episode) %>% summarize(PosSum=sum(value)) %>% select(PosSum) %>% unlist %>% unname
afinnEps$NegSum <- afinn %>% filter(value < 0) %>% group_by(Episode) %>% summarize(NegSum=sum(value)) %>% select(NegSum) %>% unlist %>% unname

ggplot(afinnEps,aes(x=Episode,group=1))+
                geom_area(aes(y=PosSum,fill="#F9D3FF"))+
                geom_area(aes(y=NegSum,fill="#B5B5B5"))+
                geom_line(aes(y=total,color="#F4B41D"),linetype="longdash",size=.4)+
                scale_fill_manual(values=c( "#440154FF","#AA1449"),name=element_blank(),labels=c("Sum of Negatively Indexed Words","Sum of Positively Indexed Words"))+
                scale_color_manual(values="#F4B41D",name=element_blank(),labels="Total Sum of Indexed Scores")+
                theme_dark()+
                theme(legend.position = "right",axis.ticks=element_blank(),legend.text = element_text(size=12),axis.title=element_text(size=12),panel.spacing.y = element_blank())+
                geom_point(aes(y=total,color="#F4B41D"))+
                labs(y="Sentiment Index")+
                scale_x_discrete(limits=c(1:25), expand = c(0, 0)) +
                geom_vline(mapping=aes(xintercept=values),color="gray30",data=SeasonCuts)+
                geom_text(aes(x=c(3,9.5,18.5),y=-400,label=lab),color="#440154FF",size=4,data=SeasonCuts)
```


<font size="3"> In general, Stranger Things tends to have more negatively indexed words than positively indexed words, as we can see from the total sum of the scores. It seems that there tends to be more positively indexed words used near the end of each season, but aside from this, there do not seem to be any obvious trends. </font>


***

```{r,echo=FALSE,message=FALSE,warning=FALSE,fig.width=5, fig.height=5, out.extra='style="float:left; padding:10px"'}
nrcSents <- get_sentiments("nrc")
ComWords <- tidy_all %>% count(word,sort=T)
ComWords <- ComWords %>% inner_join(nrcSents,by="word")
ComWords <- ComWords %>% filter(!(word == "god" & sentiment %in% c("joy", "positive","trust"))) %>% filter(!(word=="dart")) #doesn't make sense for ST

cols <- viridis::magma(8)
#c("#CC0259","#DDB800","#A50092","#1300A5","#04B1D3","#94B0B2","#9494B2","#A886AA")
cols[8] <- "maroon4"

set.seed(123)
ComWords %>%
                filter(!(sentiment %in% c("positive","negative"))) %>%
                acast(word~sentiment, value.var = "n",fill=0) %>%
                comparison.cloud(random.order = F,max.words=200,colors=cols,match.colors = T, scale=c(4,.5),title.bg.colors = "gray84",title.size=1.5,min.freq=10)

```


<font size="3"> Next, I wanted to go back to the show's most frequent words and break them up into sentiment categories as categorized by the NRC library in R. The top 200 non-neutral words of the series are encompassed in the word cloud to the left. As we can see, the most prolific categories are probably suprise and joy. I found this surprising, expecially considering the entire season sentiment graph just above.  </font>

<font size="3"> After further analysis, it seems that, while the majority of words used are negatively indexed, the range of positive words is higher than the range of negative words. </font>

<br><br><br><br><br><br><br><br><br><br>

***


<font size="3"> I then wanted to return to the most common words for each character, categorize them according to the NRC sentiment library, and see the patterns in which characters frequently used words with certain sentiments. </font>

```{r,echo=FALSE,warning=FALSE,message=FALSE,fig.width=10,error=FALSE}
sent_ComWords <- data.frame()

for(i in 1:10){
                temp <- ComWords2[[i]] %>% unlist %>% data.frame()
                temp <- left_join(temp, nrcSents %>% filter(!sentiment %in% c("positive","negative"))  ,by=c("."="word"))
                temp$Char <- rep(i,length(dim(temp)[1]))
                sent_ComWords <- bind_rows(sent_ComWords,temp)
}

temp <- data.frame(Chars=MainChars,CharNum=1:10)

sent_ComWords <- left_join(sent_ComWords,temp,by=c("Char"="CharNum"))
sent_ComWords <- sent_ComWords[,-3]
names(sent_ComWords) <- c("word","sentiment","char")
sent_ComWords$char <- factor(sent_ComWords$char)

sent_ComWords <- sent_ComWords %>% count(sentiment,char)
sent_ComWords<- sent_ComWords %>% pivot_wider(names_from = char,values_from=n) %>% data.frame()
sents <- sent_ComWords$sentiment
sent_ComWords<- data.frame(sapply(sent_ComWords[,-1],function(x) x/sum(x,na.rm=T)))
sent_ComWords$Sentiment <- factor(sents)
dup <- sent_ComWords
sent_ComWords <- sent_ComWords %>% pivot_longer(!Sentiment)



order <- sent_ComWords[is.na(sent_ComWords$Sentiment),] %>% select(name,value) %>% arrange(value) %>% select(name) %>% unlist() %>% unname

col <- viridis::magma(8)

sent_ComWords %>% mutate(name=factor(name,levels=order)) %>% 
ggplot(aes(x=name,y=value,fill=Sentiment))+
                geom_bar(stat = "identity")+
                scale_fill_manual(values=col,na.value="#545454",labels=c("Anger                  Highest:Dustin","Anticipation         Highest:Steve","Disgust                Highest:Joyce","Fear                    Highest:Eleven","Joy                      Highest:Eleven","Sadness              Highest:Eleven","Surprise              Highest:Will","Trust                   Highest:Eleven","Neutral                Highest:Hopper"))+
                theme_minimal()+
                labs(y="Percent")+
                theme_dark()+
                theme(axis.title.x=element_blank())
```

<font size="3">  As mentioned earlier, Eleven has the most one-word lines of the show. While this drives up her word length average, I  also believe this gives her the lowest percentage of neutral words, as she forgoes many common words that also might not be classified as _stop_ words. This could contribute to why she has the highest percentage of fear, joy, sadness, and trust words. Additionally, Dustin's fiery dynamic makes his placement as top percentage of anger words unsurprising. Aside from a few notable differences, the percentages across characters are similar. </font>

***

#### IMDB Rating Analysis

<font size="3"> Finally, I was curious to see how the ratings of each episode fluctated as the series progressed. I scraped the episode ratings from IMDB and got the following results: </font>

```{r, echo=FALSE,out.extra='style="float:left; padding:10px"',out.width= "65%"}
ratings$Season <- factor(EpsbySeason$Season)
temp <- ratings
temp$Episode <- str_replace_all(ratings$Episode,"_"," ")


temp %>% mutate(Episode= factor(Episode, levels=rev(Episode))) %>% 
                ggplot(aes(x=Episode,y=Ratings))+
                geom_segment(aes(col=Season,y=mean(ratings$Ratings), x=Episode, yend=Ratings, xend= Episode),size=1.5)+
                scale_colour_manual(values=c("#440154FF","#D8006C","#EAC300"))+
                geom_hline(mapping=aes(yintercept=mean(ratings$Ratings)),color="black")+
                geom_label(label=ratings$Ratings,nudge_x =0,nudge_y = 0,size=2)+
                ylim(6,9.5)+
                coord_flip()+
                labs(title="IMDB Episode Rating")+
                theme_dark()+
                theme(axis.title.y=element_blank(),plot.title = element_text(hjust=0.5,size=10))
```


```{r,fig.height=4,echo=FALSE,warning=FALSE,message=FALSE,out.extra='style="float:left; padding:10px"',out.width= "65%"}
Chars <- str_extract(AllLines$Lines,"\\w*(?=:)")
Chars <- data.frame(chars=Chars,Episode=AllLines$Episode)

MainChars2 <- c(MainChars,"Bob","Billy","Max","Robin")

LinesByMainChars <- Chars %>% group_by(Episode) %>% summarize(percent=sum(chars %in% MainChars2)/n()) %>% data.frame()

LinesByMainChars$Season <- factor(EpsbySeason$Season)
LinesByMainChars$Rating <-ratings$Ratings
Chars <- NULL

ggplot(LinesByMainChars,aes(x=Episode,group=1))+
                geom_line(aes(y=percent*10,color="Percent of Lines from Main Characters"),size=1.3)+
                geom_line(aes(y=Rating,color="Episode Rating"),size=1.3)+
                theme_gray()+
                scale_color_manual(values=c("#00004d","#009999"),name=element_blank())+
                scale_y_continuous(name="Percent By Main Characters",breaks=c(1:10),labels=seq(.1,1,.1),sec.axis = sec_axis(trans=~.*10,name="Episode Rating",breaks=c(seq(10,100,10)), labels=c(1:10)))+
                theme_dark()+
                theme(axis.title.y.left=element_text(size=9,hjust=1,vjust=2.5),,axis.title.y.right = element_text(size=9,hjust=0,vjust=2.5),legend.position = "bottom")+
                geom_vline(mapping=aes(xintercept=values),color="gray30",data=SeasonCuts)+
                geom_text(aes(x=c(3,10.5,19.5),y=3,label=lab),color="black",size=3,data=SeasonCuts)
```

<br>
<font size="3"> The trend in ratings is one of the most clear trends thus far. Given that each season represents its own color, the graph shows that IMDB scores tend to increase as the season progresses. The black vertical line represents the average of all the ratings, so we see that episodes tend to be below average the first few episodes of the season and above average for the last few episodes of the season. The exception to this trend is Episode 7 of Season 2: The Lost Sister. In this episode, Eleven leaves Hawkins to seek out her sister from the laboratory.</font>

<br>
<font size="3"> The low rating of the Lost Sister episode made me wonder if episodes that contained a higher percentage of lines from main characters had higher ratings. I calculated the percentage of lines spoken by main characters for each episode (with Max, Billy, Robin and Bob counting as main characters) and got the following results. </font>

<br>
<font size="3"> The lines somewhat follow each other, yet most notably at The Lost Sister episode. I would guess that, after removing the outlier episode, the correlation would be much weaker. </font>


<br><br>


***
***




## Feature Selection

<font size="3">
Given the statistics mentioned above, I wanted to understand which among them could help best explain variations in the IMDB rating of each episode. To do this, I used a variety of feature selection techniques, with ratings as my independent variable, to identify the most influential variables.
<br><br>
Within the dataset, each observation represents one episode and has the following features: </font>
<br>

* Percent of lines by main characters (numerical)
* Season (categorical, levels: 1,2,3)
* Number of lines from each character within each episode (numerical)
* Number of words from each character within each episode (numerical)
* Percentage of each sentiment within each episode (numerical)
   + sentiments include anger, anticipation, disgust, fear, joy, sadness, surprise, and trust
* Episode placement within each season (categorical, levels: 1-8)

<br>
<br>

#### Forward Step-Wise Selection

<font size="3">
To begin, I used forward step-wise selection as a way to find a set of variables that do a good job in explaining variation in IMDB ratings. To do this, I built several optimal models with varying numbers of features. For example, I created the optimal model with just one variable, then the optimal model with two variables, and so on and so forth. The idea is that the most influential features will be added earlier. Since we are using this technique to understand our original data better, we are not concerned with choosing the optimal number of predictors, as we would be if we were planning to build a model for prediction. The graph below shows us the R^2 value on the y-axis and the variables on the x-axis. For each level of R^2 in the graph, the variables used to achieve that level of R^2 are represented by black boxes.
</font>
```{r,echo=FALSE,results=FALSE,warning=FALSE,message=FALSE}
set.seed(11)
index = sample(1:24,18,replace = FALSE)
train = df[index,]
test = df[-index,]
errors = rep(NA,11)
regfit.fwd=regsubsets(Rating~.,data=train[,-1],nvmax=11,method="forward")

plot(regfit.fwd,scale="r2")
```
<font size="3">
<br><br>
As we can see, there are a few variables that do the bulk of the work in explaining variation, and a few others that add bit by bit. If we consider only episode placement, number of words spoken by Joyce, number of lines from Nancy, and whether the episode was in season 2 or not, we can explain a sizeable chunk of the variation.
 
<br> 
Step-wise selection does not guarantee the perfect set of predictors. For example, if two variables are highly correlated and they both explain a good portion of the data, forward step-wise selection might only use one of them because the variation the other explained may already be accounted for. Still, we can use our results as a general guide. 

Variables of importance according to forward step-wise selection:</font>
<br>

* Episode Placement
* Number of words spoken by Joyce
* Number of lines from Nancy
* Season

<br>
<br>

#### Random Forests

<font size="3"> The next method I used was random forests. Through creating 500 trees, we can see which variables were used most often to explain an episode's rating. 
</font>

```{r,echo=FALSE,include=FALSE}
rf.df = randomForest(Rating~.,data=df[,-1],nvmax=6,importance=T)
A <- varImpPlot(rf.df)
A <- as.data.frame(A)
A$Variable = rownames(A)
names(A) <- c("Perc.IncMSE","IncNodePurity","Variable")

```

```{r,fig.height=4,echo=FALSE,warning=FALSE,message=FALSE}
cols=viridis::magma(32)

A %>% mutate(Variable=fct_reorder(Variable,desc(IncNodePurity))) %>%
                ggplot(aes(x=Variable,y=IncNodePurity,fill=IncNodePurity))+
                geom_bar(stat="identity",aes(fill=IncNodePurity))+
                scale_fill_viridis_c(direction = -1)+
                theme_classic()+
                ggtitle("Importance of Variables Determined by Random Forest")+
                theme(axis.text.x = element_text(angle=90),axis.title.x=element_blank(),axis.title.y = element_blank(),plot.title = element_text(hjust=.5),legend.position = "none")

```

<font size="3">
The graph above plots the mean decrease in the gini index against the variables. The higher the value the average decrease in the gini index a variable has, the more important the variable is at explaining variation in ratings.

From the graph above, we can conclude that, according to random forests, the most important variables in explaining variation in ratings are as follows:
<br>
</font>

* Episode Placement
* Dustin's number of lines 
* Fear 

<br>
<br>


#### Ridge Regression as a Variable selector

<font size="3"> Next, I used ridge regression as a way to find important variables. Ridge regression will shrink the coefficients associated with variables that should have less influence on the model. After performing ridge regression, we can think of the variables with the largest coefficients as, by a certain measure, the most important features. </font>
```{r,echo=FALSE,warning=FALSE}
#Ridge

X.scaled = scale(df[,-c(1,3)])
df.scaled = data.frame(X.scaled, df[,3])

X = model.matrix(Rating~.,data=df.scaled)
y= df$Rating
ridge.Model = glmnet(X,y,alpha=0)
cv.ridge = cv.glmnet(X,y,alpha=0)
bestlambda = cv.ridge$lambda.min
x <- sort(round(abs(predict(ridge.Model, s=bestlambda,type="coefficients")[1:32,]),2),decreasing = TRUE)
x <- data.frame("Variable"=names(x),"Coefficient"=unname(x))
x <- x[-1,]
x <- x %>% filter(abs(Coefficient)!=0)
formattable(x,align=c(rep("l",10)))

```
<font size="3"> The table above shows the variables of the model that did not round to zero (using two decimals of precision). We can see that Episode Placement and percent of words categorized under sentiment value "fear" are most important. 

Important Variables Determined by Ridge Regression: </font>
<br>

* Episode Placement
* Fear


#### Lasso Regression as a Variable selector
<font size="3"> 
Finally, I used Lasso Regression as my last method of identifying important variables. Lasso regression is also a shrinkage method, and we can interpret the results similarly to the results of ridge regression: the largest coeffiicient are associated with the variables of most importance.
</font>

```{r,warnings=FALSE,echo=FALSE,warning=FALSE}
lasso.Model = glmnet(X,y,alpha=1)
cv.lasso = cv.glmnet(X,y,alpha=1)
bestlambda = cv.lasso$lambda.min
x=sort(round(abs(predict(lasso.Model, s=bestlambda, type="coefficients")[1:32,]),2),decreasing = TRUE)
x <- data.frame("Variable"=names(x),"Coefficient"=unname(x))
x <- x[-1,]
x <- x %>% filter(abs(Coefficient)!=0)
formattable(x,align=c(rep("l",10)))
```
<font size="3"> The output above show the coefficients that, with three digits of percision, did not round to zero. In summary and according to Lasso, the important variables in explaining IMDB ratings are the following: </font>
<br>

* Episode Placement
* Number of Words from Joyce
* Fear
* Disgust

#### Feature Selection Summary
<font size="3"> Each method of feature selection gives slightly differing results, yet all of the results grant insights into which factors affect an episode's rating. 

***

To start, every method lists Episode Placement as the most important variable, which gives us confidence in its importance as a variable. Additionally, Fear showed up as an important variable in 3 out of the 4 methods, and number of words spoken by Joyce showed up twice.

Many of the methods also displayed to us that, while there are a few very important variables, most of the variables are equally minimally important. We can see this from our ridge regression output, as most of the variables had a coefficient estimate of 0.01. Additionally, we can see this same trend in our average decrease in gini index versus variables plot under random forests. 

These results tell us that, to understand an episode's IMDB score, we must look at its placement in the season, the percentage of words classified with "fear" sentiment, the number of words from Joyce, and perhaps a few others.

***
While the results help shine light onto sources of variation of scores from existing episodes, they could also prove useful in producing the show going forward. If writers and directors understand the interactions between these variables and the IMDB ratings, they could optimize the show to the viewers' taste.

***
***






