---
title: <center>Analysis of Netflix's Stranger Things </center>
subtitle: <center> By Avery Robinson </center>
output:
  rmarkdown::html_document:
    theme: united
    highlight: tango
    toc: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r,include=FALSE}
library(tidytext)
library(dplyr)
library(stringr)
library(textdata)
library(formattable)
library(stringi)
library(tm)
library(forcats)
library(ggplot2)
library(RColorBrewer)
library(wordcloud)
library(reshape2) 
library(tidyr)
library(randomForest)
library(leaps)
library(glmnet)
```

```{r, include=FALSE}
load("originaldata.RDATA")
load("dfForAnalysis.RDATA")
df = df[,-15]
df[is.na(df)] <- 0
df= df[-15,] # Remove outlier episode
```

***

<font size="4"> Netflix's series _Stranger Things_ is one of the most influential shows of the last five years. Over forty million people viewed the third season the weekend of its release -- a Netflix record. To gain insights into my favorite show, I scraped the episode scripts for statistical analysis. I begin my report with descriptive statistics of word, speech, and sentiment patterns. Next, I analyze the IMDB ratings of each episode, and finally, I use a variety of statistical and machine learning techniques to identify variables that help explain the variation observed ratings.  </font>

***

## Descriptive Statistics and Visualizations

```{r,include=FALSE}
colors <- data.frame(color= c("#0F2970","#5B0000","#4D5463","#22847C","goldenrod2","violetred4","dodgerblue4","#02440F","saddlebrown","mediumvioletred"))
colors$Characters <- factor(MainChars)
```

```{r,fig.width=3.5,fig.height=3,echo=FALSE}

order <- Char_Stats %>% filter(Category=="TotalLines") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))

A <- Char_Stats %>% filter(Category=="TotalLines") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90,color="white")+
                geom_text(aes(label=Value,vjust=-.34),color="white",size=3)+
                theme_dark()+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title.x=element_blank(),axis.title.y=element_blank())+
                geom_text(aes(x="Nancy",y=1050, label="Total Lines"),color="black",size=5)

order <- Char_Stats %>% filter(Category == "AvgLineLength") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))


C <- Char_Stats %>% filter(Category=="AvgLineLength") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90,color="white")+
                geom_text(aes(label=round(Value,1),vjust=-.34),color="white",size=3)+
                theme_dark()+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title.x=element_blank(),axis.title.y=element_blank())+
                geom_text(aes(x="Nancy", y=10.2,label="Average # Words Per Line"),color="black",size=5)

order <- Char_Stats %>% filter(Category == "AvgWordLength") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))

D <- Char_Stats %>% filter(Category=="AvgWordLength") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90,color="white")+
                geom_text(aes(label=round(Value,1),vjust=-.34),color="white",size=3)+
                theme_dark()+
                ylim(0,5)+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title.x=element_blank(),axis.title.y=element_blank())+
                geom_text(aes(x="Hopper", y=5,label="Average Word Length"),color="black",size=5)

order <- Char_Stats %>% filter(Category == "Vocab") %>% arrange(Value) %>% select(Characters) %>% unlist %>% unname
colors <- colors %>% arrange(factor(Characters, levels=order))

E <- Char_Stats %>% filter(Category=="Vocab") %>% arrange(Value) %>% mutate(Characters=fct_reorder(Characters,Value)) %>%
                ggplot(aes(x=Characters,y=Value,fill=Characters))+
                geom_bar(stat="identity",show.legend = F)+
                scale_fill_manual(values=colors$color)+
                geom_text(aes(label=Characters,hjust=1.5),angle=90, color="white")+
                geom_text(aes(label=Value,vjust=-.34),color="white",size=3)+
                theme_dark()+
                ylim(0,1800)+
                theme(axis.text=element_blank(),axis.ticks = element_blank(), axis.title=element_blank())+
                geom_text(aes(x="Lucas", y=1770,label="Vocabulary Size"),color="black",size=5)
```


***

#### Speaking Patterns


<font size="3"> To start, I constructed several statistics on the main characters' speaking patterns:

</font>

```{r,fig.width=12,fig.height=7,echo=FALSE}
gridExtra::grid.arrange(A,C,D,E,ncol=2)
```

<font size="3"> The first aspect of these graphs that caught my eye was Eleven's top spot in "Average Word Length". I expected her to be near the bottom in each speaking-related category, yet after further analysis, it is clear that her frequent one-word lines omit typical _stop_ words -- such as "to" and "for" -- that would decrease her average.

Another aspect of interest is Dustin's placements of first for most total lines, yet fifth for median number of words per line. These dual placements suggest he is a frequent, but short, speaker.

</font>


* * *

#### Season-to-Season Line Proportion Change


<font size="3"> I was interested to find out how the roles of each character changed from season to season. Specifically, I wanted to know if their percentage of lines spoken out of all the main characters fluctuated. </font>

```{r,echo=FALSE}

dark = "aliceblue"
light = "aliceblue"

CharWordCount <- tidy_Chars %>%filter(Season==1) %>% count(Character,sort=T)
season1 <- CharWordCount %>% select(n) %>% unlist %>% unname

CharWordCount <- CharWordCount %>% mutate(total=sum(n))
CharWordCount <- CharWordCount %>% mutate(PropS1 = n/total)

Props <- data.frame(Characters=MainChars,S1=round(CharWordCount$PropS1,3))

CharWordCount <- tidy_Chars %>%filter(Season==2) %>% count(Character,sort=T)
season2 <- CharWordCount %>% select(n) %>% unlist %>% unname

CharWordCount <- CharWordCount %>% mutate(total=sum(n))
CharWordCount <- CharWordCount %>% mutate(PropS2 = n/total)

Props$S2 <- round(CharWordCount$PropS2,3)

CharWordCount <- tidy_Chars %>%filter(Season==3) %>% count(Character,sort=T)
season3 <- CharWordCount %>% select(n) %>% unlist %>% unname

CharWordCount <- CharWordCount %>% mutate(total=sum(n))
CharWordCount <- CharWordCount %>% mutate(PropS3 = n/total)

Props$S3 <- round(CharWordCount$PropS3,3)

Props <- data.frame(t(Props))

Props <- Props[-1,]


Props <- sapply(Props,as.numeric)
Props <- matrix(scales::label_percent(accuracy = .01)(Props), ncol = 10)
Props <- as.data.frame(Props)
colnames(Props) <- MainChars

Props$Season <- factor(1:3)
Props <- Props[,c("Season",MainChars)]
rownames(Props) <- NULL


formattable(Props, list("Season"=formatter("span",style=~style(color="black",font.weight="bold"))))


```

<font size="3">
I performed a chi square test to see if the characters' speaking percentages fluctuated from season to season, which proved to be true. We can see that Eleven contributed much more in seasons 2 and 3 than in season 1, which is where most of her one-word lines happened. We can also see Will's change in contribution from Season 1 to Season 2 and 3, given he spent most of Season 1 out of sight.

I was surprised to see that Steve's total percentage for Season 3 was lower than in the other seasons, yet its important to keep in mind that Season 3 had the highest number of lines of all the seasons (Season 3 had 4164 lines, while Season 2 and Season 1 had 3695 and 3413, respectively). Even though Steve had more lines in Season 3, it did not translate to him having a larger proportion of total lines from main characters.
</font>

***


#### Word Frequency Analysis

<font size="3"> I then wanted to find patterns in the specific words being used, both by the main characters and in general.</font>

<font size="3"> To start, I filtered out typical _stop_ words, calculated the most common words, and obtained the following results: </font>

```{r,echo=FALSE,message=FALSE,fig.width=12}
MostCom <- tidy_all
MostCom <- MostCom %>% count(word,sort=T)

MostCom <- MostCom %>% filter(!word %in% c("yeah","hey","uh","gonna"))

MostCom <- MostCom%>% slice_head(n=300)

MostCom %>%
                ggplot(aes(x="",y=n,label=word,color=n))+
                geom_text(position = position_jitter(seed=130,width=.55),size=6,check_overlap = T,show.legend = T)+
                scale_color_gradient(low="violetred4",high="navy")+
                theme_classic()+
                labs(color="Frequency")+
                ggtitle("Most Common Words")+
                theme_dark()+
                theme(axis.ticks=element_blank(),axis.title = element_blank(),plot.title=element_text(hjust=.5,size=16),axis.line.y=element_blank(),axis.text.x = element_blank())
                
#ggplot2::annotate("segment",x="Will",xend="Dustin",y=1700,yend=1700,colour="black",arrow=arrow())
```

<font size="3"> Naturally, we see many names near the top. We also see other familiar words up top such as "sh\*t", "god", and "guys", which are three of the most common words in the series with counts of 240, 144, and 110, respectively. </font>

***

#### Unique Words Per Character


<font size="3"> I was curious to find common words uniqe to each character. To do this, I used the tf-idf score, which stands for term frequency and inverse document frequency. This score takes into account both the frequency of the word in total and the usage of the word from each character. A word used frequently, but only by one character, would have a high tf-idf score.</font>


```{r,fig.width=15,echo=FALSE,warning=FALSE}
copy <- tidy_Chars %>% count(word,Character)
copy <- copy %>% bind_tf_idf(word,Character,n)
copy <- copy %>% arrange(desc(tf_idf))
top10 <- copy %>% group_by(Character) %>% slice_head(n=12) %>% ungroup
top10 <- top10[-c(11:12,23:24,34:35,43,45,59:60,71:72,83:84,95:96,99,101,114,118),]
top10 <- top10 %>% select(word,Character) 
top10 <- data.frame(top10)

top10$order <- factor(rep(1:10,10))
top10 <- reshape(top10, idvar = "order",timevar = "Character",direction = "wide") %>% data.frame()
top10 <- top10[,-1]
colnames(top10) <- MainChars

formattable(top10,align=c(rep("c",10)),list("Joyce"=formatter("span",style=style(color="#0F2970",font.weight="bold")),
            "Mike"=formatter("span",style=style(color="#5B0000",font.weight="bold")),
            "Hopper"=formatter("span",style=style(color="#4D5463",font.weight="bold")),
            "Nancy"=formatter("span",style=style(color="#22847C",font.weight="bold")),
            "Dustin"=formatter("span",style=style(color="#B58413",font.weight="bold")),
            "Lucas"=formatter("span",style=style(color="#99135A",font.weight="bold")),
            "Jonathan"=formatter("span",style=style(color="#186ABC",font.weight="bold")),
            "Steve"=formatter("span",style=style(color="#02440F",font.weight="bold")),
            "Will"=formatter("span",style=style(color="saddlebrown",font.weight="bold")),
            "Eleven"=formatter("span",style=style(color="mediumvioletred",font.weight="bold"))))

```

<font size="3"> Watchers of the show will observe that the words for the characters do a good job on shining light onto each personality, such as Hopper's "Smirnoff", Eleven's "mama", and Steve's "Nance".


***


#### Similarities in Speech

<font size="3"> I was also curious to find out how similarly the characters speak. I decided to focus on the aspect of common words as a metric for similarity. I found the top 100 common words per character, with _stop_ words filtered out, and calculated the intersection percentage to make the following heat map. </font>

```{r,fig.height=4,echo=FALSE,warning=FALSE,message=FALSE,out.extra='style="float:left; padding:10px"',out.width= "65%"}
ComWords2 <- tidy_Chars %>% anti_join(stop_words)
ComWords2 <- ComWords2 %>% count(Character,word,sort=T)

additionalFilter <- c("yeah","hey","gonna","um","uh")

ComWords2$word <- removeWords(ComWords2$word, additionalFilter)
ComWords2$word[ComWords2$word==""] <- NA
ComWords2 <- ComWords2[complete.cases(ComWords2),]

ComWords2 <- ComWords2 %>% arrange(Character,desc(n))
ComWords2 <- ComWords2 %>% group_by(Character)
ComWords2 = ComWords2 %>% slice_max(Character,n=100,with_ties=FALSE)
ComWords2 = as.data.frame(ComWords2)

ComWords2 <- ComWords2[,-3]
ComWords2$ID = rep(1:100,10)

ComWords2<- spread(ComWords2, Character,word)


ComWords2=ComWords2[,-1]

adjMat <- matrix(NA,ncol=10,nrow=10)
for(i in 1:10){
                for(j in 1:10){
                                adjMat[i,j]<- intersect(ComWords2[i] %>% unlist %>% unname,ComWords2[j] %>% unlist %>% unname) %>% length
                }
}

adjMat[upper.tri(adjMat)] <- NA
adjMat[adjMat==100] <- NA
adjMat <- data.frame(adjMat)

colnames(adjMat) <- MainChars
adjMat$Chars <- MainChars
adjMat <- melt(adjMat)
index <- complete.cases(adjMat)
adjMat <- adjMat[index,]

adjMat %>% mutate(Chars=factor(Chars,levels=MainChars)) %>% 
                ggplot(aes(x=Chars,y=variable,fill=value))+
                geom_tile()+
                guides(fill=guide_colorbar(ticks=F))+
                scale_fill_gradient(low="goldenrod2",high="navyblue",limits=c(10,50),breaks=c(10,50),labels=c("low","high"),aes(fill=""))+
                scale_y_discrete(position = "right")+
                theme_dark()+
                theme(axis.title=element_blank(),legend.position = "right")+
                labs(title="Commonality of Top 100 Most Common Words Per Character")

```

<br>
<font size="3"> With yellow being the lowest similarity, dark blue being the highest, and purple somewhere in the middle, we can see that the two characters with most similar speech are Joyce and Hopper. 
<br><br>
Mike's row is one of the most purple, indicating that his word usage overlaps with most of the other characters.
<br><br>
We can also see that the two characters with the least overlap in their top 100 words are Will and Eleven, the two characters with the least amount of lines. Interestly, they also seem to have the fewest words in common with each other than any other pair of characters.
<br><br>
Additionally, Nancy and Jonathan seem to speak a bit more simalrly to Joyce and Hopper than Lucas, Dustin, Will, or Eleven, yet Steve seems split between the older and younger groups.</font>


***


#### Series Sentiment Analysis


<font size="3"> After the initial word analysis, I wanted to analyze the scripts by sentiment values. Using the afinn library in R, I categorized the words of each episode as "negative", "positive", or "neutral". Each negatively and positively indexed word came with an intensity rating. For example, "afflicted" would have an intensity rating of -1, while "affection" would have an intensity rating of 3. I then summed the negatively and positively indexed words from each episode to make the following graph.

calculated the sentiment values of the words from each episode   </font>


```{r,warning=FALSE,echo=FALSE,message=FALSE,fig.width=10}
afinnSents <- get_sentiments("afinn")
afinn <- inner_join(tidy_all, afinnSents)
afinn$value[afinn$word %in% c("god","jesus")] <- -2

afinnEps<- afinn %>% group_by(Episode) %>% summarize(total=sum(value))
afinnEps <- afinnEps %>% mutate(Season=factor(c(rep(1,8),rep(2,9),rep(3,8))))

afinnEps$PosSum<- afinn %>% filter(value > 0) %>% group_by(Episode) %>% summarize(PosSum=sum(value)) %>% select(PosSum) %>% unlist %>% unname
afinnEps$NegSum <- afinn %>% filter(value < 0) %>% group_by(Episode) %>% summarize(NegSum=sum(value)) %>% select(NegSum) %>% unlist %>% unname

ggplot(afinnEps,aes(x=Episode,group=1))+
                geom_area(aes(y=PosSum,fill="#F9D3FF"))+
                geom_area(aes(y=NegSum,fill="#B5B5B5"))+
                geom_line(aes(y=total,color="#F4B41D"),linetype="longdash",size=.4)+
                scale_fill_manual(values=c( "#440154FF","#AA1449"),name=element_blank(),labels=c("Sum of Negatively Indexed Words","Sum of Positively Indexed Words"))+
                scale_color_manual(values="#F4B41D",name=element_blank(),labels="Total Sum of Indexed Scores")+
                theme_dark()+
                theme(legend.position = "right",axis.ticks=element_blank(),legend.text = element_text(size=12),axis.title=element_text(size=12),panel.spacing.y = element_blank())+
                geom_point(aes(y=total,color="#F4B41D"))+
                labs(y="Sentiment Index")+
                scale_x_discrete(limits=c(1:25), expand = c(0, 0)) +
                geom_vline(mapping=aes(xintercept=values),color="gray30",data=SeasonCuts)+
                geom_text(aes(x=c(3,9.5,18.5),y=-400,label=lab),color="#440154FF",size=4,data=SeasonCuts)
```


<font size="3"> In general, Stranger Things tends to have more negatively indexed words than positively indexed words, as we can see from the total sum of the scores represented by the yellow dashed line. Additionally, it seems that there tends to be more positively indexed words used near the end of each season, but aside from this, there do not seem to be any obvious patterns. </font>


***

#### Sentiment Analysis By Word

```{r,echo=FALSE,message=FALSE,warning=FALSE,fig.width=5, fig.height=5, out.extra='style="float:left; padding:10px"'}
nrcSents <- get_sentiments("nrc")
ComWords <- tidy_all %>% count(word,sort=T)
ComWords <- ComWords %>% inner_join(nrcSents,by="word")
ComWords <- ComWords %>% filter(!(word == "god" & sentiment %in% c("joy", "positive","trust"))) %>% filter(!(word=="dart")) #doesn't make sense for ST

cols <- viridis::magma(8)
#c("#CC0259","#DDB800","#A50092","#1300A5","#04B1D3","#94B0B2","#9494B2","#A886AA")
cols[8] <- "maroon4"

set.seed(123)
ComWords %>%
                filter(!(sentiment %in% c("positive","negative"))) %>%
                acast(word~sentiment, value.var = "n",fill=0) %>%
                comparison.cloud(random.order = F,max.words=200,colors=cols,match.colors = T, scale=c(4,.5),title.bg.colors = "gray84",title.size=1.5,min.freq=10)

```


<font size="3"> Next, I wanted to go back to the show's most frequent words and break them up into eight different sentiment categories as categorized by the NRC library in R. The top 200 non-neutral words of the series are encompassed in the word cloud to the left. As we can see, the most prolific categories are suprise and joy. While the majority of non-neutral words used in the series are negatively indexed, the range of positively indexed words is greater than the range of negatively indexed words.  </font>

<br><br><br><br><br><br><br><br><br><br><br><br>

***

#### Sentiment Analysis By Character

<font size="3"> I then wanted to return to the most common words for each character and categorize them according to the NRC sentiment library in order to discover any patterns in which characters frequently used words with certain sentiment values. </font>

```{r,echo=FALSE,warning=FALSE,message=FALSE,fig.width=10,error=FALSE}
sent_ComWords <- data.frame()

for(i in 1:10){
                temp <- ComWords2[[i]] %>% unlist %>% data.frame()
                temp <- left_join(temp, nrcSents %>% filter(!sentiment %in% c("positive","negative"))  ,by=c("."="word"))
                temp$Char <- rep(i,length(dim(temp)[1]))
                sent_ComWords <- bind_rows(sent_ComWords,temp)
}

temp <- data.frame(Chars=MainChars,CharNum=1:10)

sent_ComWords <- left_join(sent_ComWords,temp,by=c("Char"="CharNum"))
sent_ComWords <- sent_ComWords[,-3]
names(sent_ComWords) <- c("word","sentiment","char")
sent_ComWords$char <- factor(sent_ComWords$char)

sent_ComWords <- sent_ComWords %>% count(sentiment,char)
sent_ComWords<- sent_ComWords %>% pivot_wider(names_from = char,values_from=n) %>% data.frame()
sents <- sent_ComWords$sentiment
sent_ComWords<- data.frame(sapply(sent_ComWords[,-1],function(x) x/sum(x,na.rm=T)))
sent_ComWords$Sentiment <- factor(sents)
dup <- sent_ComWords
sent_ComWords <- sent_ComWords %>% pivot_longer(!Sentiment)



order <- sent_ComWords[is.na(sent_ComWords$Sentiment),] %>% select(name,value) %>% arrange(value) %>% select(name) %>% unlist() %>% unname

col <- viridis::magma(8)

sent_ComWords %>% mutate(name=factor(name,levels=order)) %>% 
ggplot(aes(x=name,y=value,fill=Sentiment))+
                geom_bar(stat = "identity")+
                scale_fill_manual(values=col,na.value="#545454",labels=c("Anger                  Highest:Dustin","Anticipation         Highest:Steve","Disgust                Highest:Joyce","Fear                    Highest:Eleven","Joy                      Highest:Eleven","Sadness              Highest:Eleven","Surprise              Highest:Will","Trust                   Highest:Eleven","Neutral                Highest:Hopper"))+
                theme_minimal()+
                labs(y="Percent")+
                theme_dark()+
                theme(axis.title.x=element_blank())
```

<font size="3">  Eleven's frequent one-word lines is the reason she has the highest percentage of non-neutral words, as she forgoes many common words that also might not be classified as _stop_ words. Aside from a few notable differences, the percentages across characters are relatively similar, and the ordering from "least neutral" to "most neutral" seems to fit the characters. </font>

***
***


## IMDB Rating Analysis

<font size="3"> Finally, I was curious to see how the ratings of each episode fluctated as the series progressed. I scraped the episode ratings from IMDB and got the following results: </font>

```{r, echo=FALSE,out.extra='style="float:left; padding:10px"',out.width= "65%"}
ratings$Season <- factor(EpsbySeason$Season)
temp <- ratings
temp$Episode <- str_replace_all(ratings$Episode,"_"," ")


temp %>% mutate(Episode= factor(Episode, levels=rev(Episode))) %>% 
                ggplot(aes(x=Episode,y=Ratings))+
                geom_segment(aes(col=Season,y=mean(ratings$Ratings), x=Episode, yend=Ratings, xend= Episode),size=1.5)+
                scale_colour_manual(values=c("#440154FF","#D8006C","#EAC300"))+
                geom_hline(mapping=aes(yintercept=mean(ratings$Ratings)),color="black")+
                geom_label(label=ratings$Ratings,nudge_x =0,nudge_y = 0,size=2)+
                ylim(6,9.5)+
                coord_flip()+
                labs(title="IMDB Episode Rating")+
                theme_dark()+
                theme(axis.title.y=element_blank(),plot.title = element_text(hjust=0.5,size=10))
```


```{r,fig.height=4,echo=FALSE,warning=FALSE,message=FALSE,out.extra='style="float:left; padding:10px"',out.width= "65%"}
Chars <- str_extract(AllLines$Lines,"\\w*(?=:)")
Chars <- data.frame(chars=Chars,Episode=AllLines$Episode)

MainChars2 <- c(MainChars,"Bob","Billy","Max","Robin")

LinesByMainChars <- Chars %>% group_by(Episode) %>% summarize(percent=sum(chars %in% MainChars2)/n()) %>% data.frame()

LinesByMainChars$Season <- factor(EpsbySeason$Season)
LinesByMainChars$Rating <-ratings$Ratings
Chars <- NULL

ggplot(LinesByMainChars,aes(x=Episode,group=1))+
                geom_line(aes(y=percent*10,color="Percent of Lines from Main Characters"),size=1.3)+
                geom_line(aes(y=Rating,color="Episode Rating"),size=1.3)+
                theme_gray()+
                scale_color_manual(values=c("#00004d","#009999"),name=element_blank())+
                scale_y_continuous(name="Percent By Main Characters",breaks=c(1:10),labels=seq(.1,1,.1),sec.axis = sec_axis(trans=~.*10,name="Episode Rating",breaks=c(seq(10,100,10)), labels=c(1:10)))+
                theme_dark()+
                theme(axis.title.y.left=element_text(size=9,hjust=1,vjust=2.5),,axis.title.y.right = element_text(size=9,hjust=0,vjust=2.5),legend.position = "bottom")+
                geom_vline(mapping=aes(xintercept=values),color="gray30",data=SeasonCuts)+
                geom_text(aes(x=c(3,10.5,19.5),y=3,label=lab),color="black",size=3,data=SeasonCuts)
```

<br>
<font size="3"> The trend in ratings is one of the most clear trends thus far. Given that each season represents its own color, the graph shows that IMDB scores tend to increase as the season progresses. The black vertical line represents the average of all the ratings, so we see that episodes tend to be below average the first few episodes of the season and above average for the last few episodes of the season. The exception to this trend is Episode 7 of Season 2: The Lost Sister. </font>

<br>
<font size="3"> The Lost Sister episode mainly contained only one main character, which made me wonder if episodes with higher percentages of lines from main characters tended to rate higher.I calculated the percentage of lines spoken by main characters for each episode and obtained the following results. </font>

<br>
<font size="3"> The lines somewhat follow each other, yet most notably at The Lost Sister episode. I would guess that, after removing the outlier episode, the correlation would be much weaker. </font>


<br><br><br><br><br><br>


***
***

<br>

## Feature Selection

<font size="3">
It is clear that episode placement within each season is influential to an episode's IMDB rating. I was curious to find out which of the other statistics mentioned above might also have influence. In order to explore this question, I used a variety of machine learning techniques with different feature selection properties and compared results. I started with forward stepwise selection, moved on to random forests, and ended with ridge and lasso regression. </font>
```{r,echo=FALSE}
#I began with the correlations of each numerical predictor with the independent variable of IMDB rating: 
tab = cor(df[,4],df[,-c(1,3:4)])
tab = data.frame("Var"=colnames(tab),"Cor"=as.vector(tab))
tab = arrange(tab,desc(abs(Cor)))
#formattable(tab[1:10,],align=rep("l",7))
# These correlations give us a good idea as to which variables are important, but they do not account for nonlinear relationships.
```


<br>

#### Forward Step-Wise Selection

<font size="3">
To implement forward stepwise selection , I built several optimal models with varying numbers of features using a greedy algorithm. Roughly speaking, we can think of the order in which variables are added as an order of importance of the variables. 

The graph below shows us the R^2 value on the y-axis and the variables on the x-axis. For each level of R^2 in the graph, the variables used to achieve that level of R^2 are represented by black boxes.
</font>
```{r,echo=FALSE,results=FALSE,warning=FALSE,message=FALSE}
set.seed(11)
index = sample(1:24,18,replace = FALSE)
train = df[index,]
test = df[-index,]
errors = rep(NA,11)
regfit.fwd=regsubsets(Rating~.,data=train[,-1],nvmax=11,method="forward")

plot(regfit.fwd,scale="r2")
```
<font size="3">
<br><br>
As we can see, there are a few variables that do the bulk of the work in explaining variation, and a few others that add bit by bit. If we consider only episode placement, number of words spoken by Joyce, number of lines from Nancy, and whether the episode was in season 2 or not, we can explain a sizeable chunk of the variation.

Step-wise selection does not guarantee the perfect set of predictors, both because of the nature of greedy algorithms and issues with correlated variables. To avoid multicollinearity problems, the algorithm will not want to add two variables that are highly correlated to the model, even if they are both influential to ratings. Still, we can use our results as a general guide. 

Variables of importance according to forward step-wise selection:</font>
<br>

* Episode Placement
* Number of words spoken by Joyce
* Number of lines from Nancy
* Season

***
<br>

#### Random Forests

<font size="3"> The next method I used was random forests. Through creating 500 trees, we can see which variables were used most often to explain an episode's rating. 
</font>

```{r,echo=FALSE,include=FALSE}
rf.df = randomForest(Rating~.,data=df[,-1],nvmax=6,importance=T)
A <- varImpPlot(rf.df)
A <- as.data.frame(A)
A$Variable = rownames(A)
names(A) <- c("Perc.IncMSE","IncNodePurity","Variable")

```

```{r,fig.height=4,echo=FALSE,warning=FALSE,message=FALSE}
cols=viridis::magma(32)

A %>% mutate(Variable=fct_reorder(Variable,desc(IncNodePurity))) %>%
                ggplot(aes(x=Variable,y=IncNodePurity,fill=IncNodePurity))+
                geom_bar(stat="identity",aes(fill=IncNodePurity))+
                scale_fill_viridis_c(direction = -1)+
                theme_classic()+
                ggtitle("Importance of Variables Determined by Random Forest")+
                theme(axis.text.x = element_text(angle=90),axis.title.x=element_blank(),axis.title.y = element_blank(),plot.title = element_text(hjust=.5),legend.position = "none")

```

<font size="3">
The graph above plots the mean decrease in the gini index against the variables. In general, the higher the value the average decrease in the gini index a variable has, the more important the variable is at explaining variation in ratings.

From the graph above, we can conclude that, according to random forests, the most important variables in explaining variation in ratings are as follows:
<br>
</font>

* Episode Placement
* Dustin's number of lines 
* Fear 

***
<br>


#### Ridge Regression as a Variable selector

<font size="3"> Next, I used ridge regression. Ridge regression will shrink the coefficients associated with variables that should have less influence on the model, and therefore, we can think of the variables with the largest coefficients as, by a certain measure, the more important features. </font>
```{r,echo=FALSE,warning=FALSE}
#Ridge

X.scaled = scale(df[,-c(1,3)])
df.scaled = data.frame(X.scaled, df[,3])

X = model.matrix(Rating~.,data=df.scaled)
y= df$Rating
ridge.Model = glmnet(X,y,alpha=0)
cv.ridge = cv.glmnet(X,y,alpha=0)
bestlambda = cv.ridge$lambda.min
x <- sort(round(abs(predict(ridge.Model, s=bestlambda,type="coefficients")[1:32,]),2),decreasing = TRUE)
x <- data.frame("Variable"=names(x),"Coefficient"=unname(x))
x <- x[-1,]
x <- x %>% filter(abs(Coefficient)!=0)
formattable(x,align=c(rep("l",10)))

```
<font size="3"> The table above shows the variables of the model that did not round to zero (using two decimals of precision). 

Important Variables Determined by Ridge Regression: </font>
<br>

* Episode Placement
* Fear

***
<br>
<br>


#### Lasso Regression as a Variable selector
<font size="3"> 
Finally, I used Lasso Regression as my last method of identifying important variables. Lasso regression is also a shrinkage method, and we can interpret the results similarly to those of ridge regression.
</font>

```{r,warnings=FALSE,echo=FALSE,warning=FALSE}
lasso.Model = glmnet(X,y,alpha=1)
cv.lasso = cv.glmnet(X,y,alpha=1)
bestlambda = cv.lasso$lambda.min
x=sort(round(abs(predict(lasso.Model, s=bestlambda, type="coefficients")[1:32,]),2),decreasing = TRUE)
x <- data.frame("Variable"=names(x),"Coefficient"=unname(x))
x <- x[-1,]
x <- x %>% filter(abs(Coefficient)!=0)
formattable(x,align=c(rep("l",10)))
```
<font size="3"> The output above shows the coefficients that, with three digits of percision, did not round to zero. According to Lasso regression , the important variables in explaining IMDB ratings are the following: </font>
<br>

* Episode Placement
* Number of Words from Joyce
* Fear
* Disgust

<br>
<br>

***

#### Feature Selection Summary

<font size="3"> The overlapping results from each method of feature selection allows us to confidently conclude, as we assumed beforehand, that episode placement is the most influential variable in explaining the variation in ratings. It seems that fear, disgust, season, and number of words or lines from Joyce, Dustin, and Nancy all have some amount of influence as well. 

Through the different outputs, we also can observe that, while a few variables are highly important, many variables are just slightly important. We can see this in the numerous "0.01" coefficients given by Ridge Regression and the thin tail of the right-skewed plot in the random forests section.  

In summary, episode placement is the most powerful explanatory variable when it comes to the IMDB ratings, which leads us to believe that fans tend to enjoy the faster-paced, thrill-filled and conclusive episodes the most.

</font>


***
***






